# hamagin-knowledge-graph-RAG-llm-agents
This repository implements a RAG system designed to reduce hallucination in LLMs. The project focuses on a loan screening document generation use case for Hamagin (The Bank of Yokohama, 横浜銀行), integrating both knowledge extraction and evaluation models to ensure factual consistency, domain alignment, and decision transparency.

# 背景
横浜銀行に過去に蓄積された融資稟議書から稟議書作成知識を取り出す。
課題: 3000件の融資稟議書からPoCで稟議書作成知識を抽出する。ゆえに「人手で情報の妥当性を判断することに膨大な時間がかかる」つまり、ほぼ不可能。

# 分析
大きく分けて三つのアプローチがある。(すべてを同時採用可能)

## 1: 生成段階のHallucinationを減らす。
結論から言うと、「ドメイン知識を使用する」ことがカギになる。技術的にはRAGを使用することになる。RAGを使用することで(1)業界情報や(2)各社情報を入力として与えて、さらに参照した情報をソースとして明言することができる。
この際に「知識グラフ」を使用することが効果的である可能性がある。なぜならグラフ形式で金融知識とくに用語同士の関係をグラフのエッジで明示化できるからである。その他のデータベースの形式だと文書をチャンクで分ける際に、関係性のある用語同士が、別のチャンクに割り振られてしまい、複数段階の推論を行う際に関係性が参照されないという問題がある。
注: 通常のデータベースとグラフベースは競合しないので併用可能である。

## 2: 評価段階に別のモデルあるいはペルソナを使用する。
結論から言うと、アンサンブル的な手法で、前段階の出力を評価することに特化したモデルや、専門知識をもったLLMのペルソナを設定して、妥当性を判断する。
イメージとしては多数決が近い。一つのモデルがハルシネーションを起こす確率がPだとしても、複数の評価モデルが同時にハルシネーションを起こす確率は、単純化されてはいるが指数関数的に減少するので、出力の真正性を担保することができる。(ただし、質が高いかは別である。)

## 3: 評価結果を生成モデルにフィードバックを与え、再度生成する。
前段階で得られた評価をもとに、ソースが足りない部分や、ハルシネーションが起こっている部分を指摘して、生成モデルに修正させる段階。
可能であれば、融資稟議に関する知識を具体的にするように、追加項目を評価モデルが指定できるようになれば、抽出された知識の質を向上させることができる。
なので、どのような特徴量やパラメータを、フィードバックとして与えるかを調査する必要がある。

# おすすめ
生成モデル + 評価モデル + (もしかするとweb等の情報収集モデル) の複数のモデルが互いに連携する必要があるので、LangGraphを使用してLLM Agentのシステムを実装するのが一番、効果的であると認識しています。

検討しているアーキテクチャは大きく分けて以下の2つ
1: 全体の複数モデルを指揮統括するリーダモデルを設定して、垂直型の設計を採用
2: それぞれのモデルが互いに独立して機能を遂行する水平型の設計を採用